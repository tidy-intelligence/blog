{
  "hash": "455db79e5d8ff3ac66d531422f216363",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tidy Classification Models: Customer Churn Prediction\"\ndescription: \"A comparison of classification approaches using the tidymodels package\"\nmetadata:\n  pagetitle: \"Tidy Classification Models\"\nauthor: \"Christoph Scheuch\"\ndate: \"2024-02-22\" \nimage: thumbnail.png\nimage-alt: A squirrel sitting in a bright and friendly office, curiously looking at an old-fashioned rotary dial telephone on a wooden desk. Sunlight filters through the window, creating a warm, welcoming atmosphere. The office is decorated with vibrant green plants in terracotta pots and bookshelves filled with colorful books. Created with DALL-E 3.\ncategories: \n  - R\n  - Modeling\ndraft: true\nexecute: \n  cache: true\n---\n\n\n...\n\n`tidymodels` is an ecosystem of R packages designed for data modeling and statistical analysis that adheres to the principles of the `tidyverse`. It provides a comprehensive framework for building and evaluating models, streamlining workflows from data preprocessing and feature engineering to model training, validation, and finte-tuning. It also provides a unified interface for various modeling techniques, `tidymodels` simplifies the process of creating reproducible and scalable data analysis pipelines, catering to both novice and experienced data scientists.\n\n...\n\n## Load packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(glmnet)\nlibrary(ranger)\nlibrary(xgboost)\nlibrary(torch)\nlibrary(brulee)\nlibrary(readr)\nlibrary(janitor)\nlibrary(stringr)\n```\n:::\n\n\n\n## Download & clean data\n\n- We only use 11 observations by dropping all rows with a missing value, so I'm not going into details here. \n- Remove `customer_id` because we don't need it for pre-processing\n- Apply one-hot encoding to the remaining variables later\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_url <- \"https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv\"\ncustomer_raw <- read_csv(data_url) \n\ncustomer <- customer_raw |> \n  clean_names() |> \n  select(-customer_id) |> \n  na.omit() |> \n  mutate(churn = factor(if_else(churn==\"Yes\", 1L, 0L)),\n         female = if_else(gender==\"Female\", 1L, 0L),\n         senior_citizen = as.integer(senior_citizen)) |> \n  select(-gender) |> \n  mutate(\n    across(c(partner, dependents, phone_service, paperless_billing), \n           ~if_else(. == \"Yes\", 1L, 0L)),\n    across(c(multiple_lines, internet_service, online_security, online_backup, \n             device_protection, tech_support, streaming_tv, streaming_movies,\n             contract, paperless_billing, payment_method),\n           ~str_to_lower(str_replace_all(., \" |\\\\-\", \"_\")))\n    ) \n\nset.seed(1234)\ncustomer_split <- initial_split(customer, prop = 4/ 5, strata = churn)\ncustomer_folds <- vfold_cv(training(customer_split), v = 5, strata = churn)\n```\n:::\n\n\n## Pre-process data\n\n- Standardize all double variables\n- One-hot encode all remaining categorical variables\n- Important to keep that order, otherwise the encoded variables are also standardized!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_recipe <- recipe(churn ~ ., data = training(customer_split)) |> \n  step_log(c(total_charges)) |> \n  step_normalize(c(tenure, monthly_charges)) |>\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncustomer_workflow <- workflow() |> \n  add_recipe(customer_recipe)\n```\n:::\n\n\n## Build models\n\n::: {.panel-tabset}\n### Logistic regression\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_logistic <- logistic_reg(penalty = 0.0001, mixture = 1) |>\n  set_engine(\"glmnet\") |> \n  set_mode(\"classification\")\n```\n:::\n\n\n### Random Forest\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_random_forest <- rand_forest() |>\n  set_engine(\"ranger\") |>\n  set_mode(\"classification\")\n```\n:::\n\n\n### XGBoost\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_xgboost <- boost_tree() |>\n  set_engine(\"xgboost\") |>\n  set_mode(\"classification\")\n```\n:::\n\n\n### K-nearest neighbor\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_knn <- nearest_neighbor(neighbors = 4) |>\n  set_engine(\"kknn\") |>\n  set_mode(\"classification\")\n```\n:::\n\n\n### Neural network\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_neural_net <- mlp(epochs = 500, hidden_units = 10) |>\n  set_engine(\"brulee\") |>\n  set_mode(\"classification\") \n```\n:::\n\n\n## Fit models on training data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_metrics_training <- function(spec) {\n  customer_workflow |> \n    add_model(spec) |> \n    fit_resamples(\n      resamples = customer_folds,\n      metrics = metric_set(recall, precision, accuracy),\n      control = control_resamples(save_pred = TRUE)\n    ) |> \n    collect_metrics(summarize = TRUE) |> \n    mutate(model = attributes(spec)$class[1])\n}\n\nmetrics_training <- list(\n  spec_logistic, spec_random_forest, spec_xgboost, \n  spec_knn, spec_neural_net\n) |> \n  map_df(create_metrics_training)\n```\n:::\n\n\n## Evaluate models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics_training |> \n  mutate(ci_lower = mean - std_err / sqrt(n) * qnorm(0.99),\n         ci_upper = mean + std_err / sqrt(n) * qnorm(0.99)) |> \n  ggplot(aes(x = mean, y = model, fill = model)) +\n  geom_col() + \n  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = .2,\n                position = position_dodge(.9)) +\n  facet_wrap(~.metric, ncol = 1) +\n  labs(x = NULL, y = NULL,\n       title = \"Comparison of metrics for different classification models\",\n       subtitle = \"Based on training data\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  coord_cartesian(xlim = c(0, 1)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=2100}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncreate_metrics_test <- function(spec) {\n\n  test_predictions <-  customer_workflow |>\n    add_model(spec) |> \n    fit(data =  training(customer_split)) |> \n    predict(new_data = testing(customer_split))\n  \n  test_results <- bind_cols(testing(customer_split), test_predictions)\n  \n  bind_rows(\n    recall(test_results, truth = churn, estimate = .pred_class),\n    precision(test_results, truth = churn, estimate = .pred_class),\n    accuracy(test_results, truth = churn, estimate = .pred_class)\n  ) |> \n    mutate(model = attributes(spec)$class[1])\n}\n\nmetrics_test <- list(\n  spec_logistic, spec_random_forest, spec_xgboost, \n  spec_knn, spec_neural_net\n) |> \n  map_df(create_metrics_test)\n\nmetrics <- bind_rows(\n  metrics_training |> \n    mutate(sample = \"Training\") |> \n    select(metric = .metric, estimate = mean, model, sample),\n  metrics_test |> \n    mutate(sample = \"Test\") |> \n    select(metric = .metric, estimate = .estimate, model, sample)\n) \n\nmetrics |> \n  ggplot(aes(x = estimate, y = model, fill = sample)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~metric, ncol = 1) +\n  labs(x = NULL, y = NULL, fill = \"Sample\",\n       title = \"Comparison of metrics for different classification models\",\n       subtitle = \"Training is the mean across 5-fold cross validation results, Test is based on 20% of the initial data\") +\n  theme_minimal() +\n  coord_cartesian(xlim = c(0, 1)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=2100}\n:::\n:::\n\n\n## Tune models\n\n::: {.panel-tabset}\n### Logistic regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_logistic_tune <- logistic_reg(\n  penalty = tune(), \n  mixture = tune()\n) |>\n  set_engine(\"glmnet\") |> \n  set_mode(\"classification\")\n\ngrid_logistic <- grid_regular(\n  penalty(range = c(-10, 0), trans = log10_trans()),\n  mixture(range = c(0, 1)),\n  levels = 5 \n)\n\ntune_logistic <- tune_grid(\n  customer_workflow |> \n    add_model(spec_logistic_tune),\n  resamples = customer_folds,\n  grid = grid_logistic,\n  metrics = metric_set(recall, precision, accuracy) \n)\n\ntuned_model_logistic <- finalize_model(\n  spec_logistic_tune, select_best(tune_logistic, \"accuracy\")\n)\ntuned_model_logistic\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 0\n\nComputational engine: glmnet \n```\n\n\n:::\n:::\n\n\n### Random forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_random_forest_tune <- rand_forest(\n  mtry = tune(), \n  min_n = tune()\n) |>\n  set_engine(\"ranger\") |>\n  set_mode(\"classification\")\n\ngrid_random_forest <- grid_regular(\n  mtry(range = c(1, 5)),\n  min_n(range = c(2, 40)),\n  levels = 5\n)\n\ntune_random_forest  <- tune_grid(\n  customer_workflow |> \n    add_model(spec_random_forest_tune),\n  resamples = customer_folds,\n  grid = grid_random_forest,\n  metrics = metric_set(recall, precision, accuracy) \n)\n\ntuned_model_random_forest <- finalize_model(\n  spec_random_forest_tune, select_best(tune_random_forest, \"accuracy\")\n)\ntuned_model_random_forest\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRandom Forest Model Specification (classification)\n\nMain Arguments:\n  mtry = 5\n  min_n = 21\n\nComputational engine: ranger \n```\n\n\n:::\n:::\n\n\n### XGBoost\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspec_xgboost_tune <- boost_tree(\n  mtry = tune(), \n  min_n = tune()\n) |>\n  set_engine(\"xgboost\") |>\n  set_mode(\"classification\")\n\ngrid_xgboost <- grid_regular(\n  mtry(range = c(1L, 5L)),\n  min_n(range = c(1L, 40L)),\n  levels = 5\n)\n\ntune_xgboost  <- tune_grid(\n  customer_workflow |> \n    add_model(spec_xgboost_tune),\n  resamples = customer_folds,\n  grid = grid_xgboost,\n  metrics = metric_set(recall, precision, accuracy) \n)\n\ntuned_model_xgboost <- finalize_model(\n  spec_xgboost_tune, select_best(tune_xgboost, \"accuracy\")\n)\ntuned_model_xgboost\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBoosted Tree Model Specification (classification)\n\nMain Arguments:\n  mtry = 5\n  min_n = 40\n\nComputational engine: xgboost \n```\n\n\n:::\n:::\n\n\n### K-nearest neighbor\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid_knn <- grid_regular(\n  neighbors(range = c(1L, 20L)),\n  levels = 5 \n)\n\nspec_knn_tune <- nearest_neighbor(\n  neighbors = tune()\n) |>\n  set_engine(\"kknn\") |>\n  set_mode(\"classification\")\n\ntune_knn <- tune_grid(\n  customer_workflow |> \n    add_model(spec_knn_tune),\n  resamples = customer_folds,\n  grid = grid_knn,\n  metrics = metric_set(recall, precision, accuracy) \n)\n\ntuned_model_knn <- finalize_model(spec_knn_tune, select_best(tune_knn, \"accuracy\"))\ntuned_model_knn\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nK-Nearest Neighbor Model Specification (classification)\n\nMain Arguments:\n  neighbors = 20\n\nComputational engine: kknn \n```\n\n\n:::\n:::\n\n\n### Neural net\n\n\n::: {.cell messag='false'}\n\n```{.r .cell-code}\ngrid_neural_net <- grid_regular(\n  hidden_units(range = c(1L, 10L)),\n  epochs(range = c(10L, 1000L)),\n  levels = 5 \n)\n\nspec_neural_net_tune <- mlp(\n  epochs = tune(), \n  hidden_units = tune()\n) |>\n  set_engine(\"brulee\") |>\n  set_mode(\"classification\") \n\ntune_neural_net <- tune_grid(\n  customer_workflow |> \n    add_model(spec_neural_net_tune),\n  resamples = customer_folds,\n  grid = grid_neural_net,\n  metrics = metric_set(recall, precision, accuracy) \n)\n\ntuned_model_neural_net <- finalize_model(spec_neural_net_tune, select_best(tune_neural_net, \"accuracy\"))\ntuned_model_neural_net\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSingle Layer Neural Network Model Specification (classification)\n\nMain Arguments:\n  hidden_units = 10\n  epochs = 505\n\nComputational engine: brulee \n```\n\n\n:::\n:::\n\n\n::: \n\n## Comparing tuned models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics_tuned <- list(\n  tuned_model_logistic, tuned_model_random_forest, tuned_model_xgboost,\n  tuned_model_knn, tuned_model_neural_net\n) |> \n  map_df(create_metrics_test)\n\nmetrics_comparison <- bind_rows(\n  metrics,\n  metrics_tuned |> \n    mutate(sample = \"Tuned\") |> \n    select(metric = .metric, estimate = .estimate, model, sample)\n)\n\nmetrics_comparison |> \n  filter(metric == \"accuracy\") |> \n  ggplot(aes(x = estimate, y = model, fill = sample)) +\n  geom_col(position = \"dodge\") +\n  facet_wrap(~metric, ncol = 1) +\n  labs(x = NULL, y = NULL, fill = \"Sample\",\n       title = \"Comparison of accuracy for different classification models\",\n       subtitle = \"Training is the mean across 5-fold cross validation results, Test is based on 20% of the initial data\") +\n  theme_minimal() +\n  coord_cartesian(xlim = c(0, 1)) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=2100}\n:::\n:::\n\n\nWhich model has on average the best rank? \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmetrics_comparison |> \n  group_by(sample, metric) |> \n  arrange(-estimate) |> \n  mutate(rank = row_number()) |> \n  group_by(model) |> \n  summarize(rank = mean(rank)) |> \n  arrange(rank)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 Ã— 2\n  model             rank\n  <chr>            <dbl>\n1 logistic_reg      2.11\n2 mlp               2.22\n3 rand_forest       2.44\n4 boost_tree        3.22\n5 nearest_neighbor  5   \n```\n\n\n:::\n:::\n\n\n## Concluding remarks\n\nWhat I love most about `tidymodels` is its scalability with respect to models and metrics. You can quickly prototype different approaches using very little code. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}