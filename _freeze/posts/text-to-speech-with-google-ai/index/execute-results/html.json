{
  "hash": "bd8cfdddf803def47751c805ba10217d",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Text-to-Speech with Goolge AI\"\ndescription: \"Creating an audio book using Google's Text-to-Speech API\"\nmetadata:\n  pagetitle: \"Text-to-Speech with Goolge AI\"\nauthor: \"Christoph Scheuch\"\ndate: \"2025-02-24\" \nimage: thumbnail.png\nimage-alt: A whimsical illustration of a bug lying on its back in a cozy office setting. Sunlight streams through a large window, creating a warm and welcoming atmosphere. The office is decorated with vibrant green plants in terracotta pots and bookshelves filled with colorful books. The bug appears relaxed and content, adding a playful touch to the cheerful environment. Created with DALL-E.\ncategories: \n  - Python\n  - Text-to-Speech AI\n---\n\n\nLately, I’ve found myself increasingly drawn to audiobooks and became curious about how I could create one myself using AI. In this post, I’ll walk you through how to leverage Google’s powerful Text-to-Speech (TTS) API to transform written content into high-quality audio. As an example, we’ll use the first chapter of Franz Kafka’s The Metamorphosis and turn this classic piece of literature into an audiobook - step by step.\n\nBefore we dive into generating our audiobook, let’s set up the Python environment with the necessary libraries. We’ll use Google Cloud’s Text-to-Speech client to convert text into speech, along with some utility libraries for handling environment variables and audio processing.\n\nThe key packages we’ll need are:\n- `google-cloud-texttospeech`: Google’s official client library for the Text-to-Speech API.\n- `pydub`: A simple and easy-to-use library for audio manipulation.\n- `python-dotenv`: To securely load API keys and configuration from a .env file.\n\n::: {#5f88d544 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport time\nimport re\n\nfrom dotenv import load_dotenv\nfrom google.cloud import texttospeech\nfrom pydub import AudioSegment\n\nload_dotenv()\n```\n:::\n\n\n## Prepare Text\n\nTo begin, we need the text we want to convert into audio. I downloaded the first chapter of Franz Kafka’s The Metamorphosis from [Project Gutenberg](https://www.gutenberg.org/cache/epub/5200/pg5200.txt), which offers a vast collection of public domain books.\n\n::: {#52695424 .cell execution_count=2}\n``` {.python .cell-code}\nwith open(\"metamorphosis_chapter1.txt\", \"r\", encoding=\"utf-8\") as file:\n    text = file.read()\n\ntext[:500]\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n'One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin. He lay on his\\narmour-like back, and if he lifted his head a little he could see his\\nbrown belly, slightly domed and divided by arches into stiff sections.\\nThe bedding was hardly able to cover it and seemed ready to slide off\\nany moment. His many legs, pitifully thin compared with the size of the\\nrest of him, waved about helplessly as he looked.\\n\\n“What’s happened to me?” he th'\n```\n:::\n:::\n\n\nBefore moving forward, skim through the loaded text to ensure there aren’t any unwanted headers, footers, or formatting issues (like excessive line breaks) that might affect the audio quality or API compatibility. \n\nOne of the challenges in working with text-to-speech APIs is handling large chunks of text. Google's API has limitations on input size, so we need to split our text intelligently. The following approach breaks the text into manageable paragraphs while preserving the natural flow of the narrative. It splits text on double line breaks (paragraphs), ensures each chunk stays within a 2000-byte limit, and  maintains paragraph integrity where possible.\n\n::: {#204ed6ab .cell execution_count=3}\n``` {.python .cell-code}\ndef split_text_by_paragraphs(\n    text: str, \n    max_bytes: int = 2000\n) -> list[str]:\n    \"\"\"\n    Split the text into chunks based on paragraphs (empty lines) and ensure each chunk is within the byte limit.\n\n    Args:\n        text (str): The input text to split.\n        max_bytes (int): Maximum byte size for each chunk.\n\n    Returns:\n        list[str]: List of text chunks.\n    \"\"\"\n    paragraphs = text.split(\"\\n\\n\")\n    chunks = []\n    current_chunk = \"\"\n    current_bytes = 0\n\n    for paragraph in paragraphs:\n        paragraph_bytes = len(paragraph.encode(\"utf-8\"))\n        if current_bytes + paragraph_bytes + 1 > max_bytes:\n            chunks.append(current_chunk.strip())\n            current_chunk = paragraph\n            current_bytes = paragraph_bytes\n        else:\n            if current_chunk:\n                current_chunk += \"\\n\\n\" + paragraph\n            else:\n                current_chunk = paragraph\n            current_bytes += paragraph_bytes + 2 \n\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n\n    return chunks\n```\n:::\n\n\nLet's create paragraphs and inspect the first one:\n\n::: {#bdfffa4b .cell execution_count=4}\n``` {.python .cell-code}\nparagraphs = split_text_by_paragraphs(text)\nlen(paragraphs)\nparagraphs[0]\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n'One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin. He lay on his\\narmour-like back, and if he lifted his head a little he could see his\\nbrown belly, slightly domed and divided by arches into stiff sections.\\nThe bedding was hardly able to cover it and seemed ready to slide off\\nany moment. His many legs, pitifully thin compared with the size of the\\nrest of him, waved about helplessly as he looked.\\n\\n“What’s happened to me?” he thought. It wasn’t a dream. His room, a\\nproper human room although a little too small, lay peacefully between\\nits four familiar walls. A collection of textile samples lay spread out\\non the table—Samsa was a travelling salesman—and above it there hung a\\npicture that he had recently cut out of an illustrated magazine and\\nhoused in a nice, gilded frame. It showed a lady fitted out with a fur\\nhat and fur boa who sat upright, raising a heavy fur muff that covered\\nthe whole of her lower arm towards the viewer.\\n\\nGregor then turned to look out the window at the dull weather. Drops of\\nrain could be heard hitting the pane, which made him feel quite sad.\\n“How about if I sleep a little bit longer and forget all this\\nnonsense”, he thought, but that was something he was unable to do\\nbecause he was used to sleeping on his right, and in his present state\\ncouldn’t get into that position. However hard he threw himself onto his\\nright, he always rolled back to where he was. He must have tried it a\\nhundred times, shut his eyes so that he wouldn’t have to look at the\\nfloundering legs, and only stopped when he began to feel a mild, dull\\npain there that he had never felt before.'\n```\n:::\n:::\n\n\nRaw text often contains formatting that doesn't translate well to speech or even triggers error codes in the API. The following `clean_chunk()` function emerged in another project that I was working on and prepares the text by: converting single line breaks to spaces, removing double periods, cleaning up special characters and quotation marks, eliminating parenthetical content, and handling Unicode and control characters. This cleaning process is crucial for producing natural-sounding speech without awkward pauses or artifacts. Note that the function below is not generally applicable and needs to be adapted to your specific context.\n\n::: {#1cdc11c5 .cell execution_count=5}\n``` {.python .cell-code}\ndef clean_chunk(chunk) -> str: \n    \"\"\"\n    Cleans and formats a text chunk by removing unwanted characters, normalizing whitespace, and improving readability.\n\n    Args:\n        chunk (str): The text chunk to be cleaned.\n\n    Returns:\n        str: The cleaned and formatted text.\n    \"\"\"\n    cleaned_chunk = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', chunk) \n    cleaned_chunk = re.sub(r'\\n{2,}', '. ', cleaned_chunk)\n    cleaned_chunk = cleaned_chunk.replace(\"..\", \".\").replace(\"»\", \"\").replace(\"«\", \"\")\n    cleaned_chunk = re.sub(r'\\s-\\s+', '', cleaned_chunk)\n    cleaned_chunk = re.sub(r'\\([^)]*\\)', '', cleaned_chunk).strip()\n    cleaned_chunk = cleaned_chunk.replace(\"\\u2028\", \" \")\n    cleaned_chunk = re.sub(r'[\\x00-\\x1F\\x7F-\\x9F]', ' ', cleaned_chunk)\n\n    return cleaned_chunk\n\nclean_chunk(paragraphs[0])\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\n'One morning, when Gregor Samsa woke from troubled dreams, he found himself transformed in his bed into a horrible vermin. He lay on his armour-like back, and if he lifted his head a little he could see his brown belly, slightly domed and divided by arches into stiff sections. The bedding was hardly able to cover it and seemed ready to slide off any moment. His many legs, pitifully thin compared with the size of the rest of him, waved about helplessly as he looked. “What’s happened to me?” he thought. It wasn’t a dream. His room, a proper human room although a little too small, lay peacefully between its four familiar walls. A collection of textile samples lay spread out on the table—Samsa was a travelling salesman—and above it there hung a picture that he had recently cut out of an illustrated magazine and housed in a nice, gilded frame. It showed a lady fitted out with a fur hat and fur boa who sat upright, raising a heavy fur muff that covered the whole of her lower arm towards the viewer. Gregor then turned to look out the window at the dull weather. Drops of rain could be heard hitting the pane, which made him feel quite sad. “How about if I sleep a little bit longer and forget all this nonsense”, he thought, but that was something he was unable to do because he was used to sleeping on his right, and in his present state couldn’t get into that position. However hard he threw himself onto his right, he always rolled back to where he was. He must have tried it a hundred times, shut his eyes so that he wouldn’t have to look at the floundering legs, and only stopped when he began to feel a mild, dull pain there that he had never felt before.'\n```\n:::\n:::\n\n\n## Convert Text to Speech\n\nThe heart of our solution lies in the `text_to_speech()` function, which interfaces with Google's API. I've configured it with specific parameters to create a more engaging listening experience: aAdjusting pitch (-20) for a more natural sound and setting to a comfortable speaking rate (0.8). The function includes error handling and retry logic, making it robust enough for processing longer texts like books.\n\n::: {#1b2604ea .cell execution_count=6}\n``` {.python .cell-code}\ndef text_to_speech(\n    text: str, \n    output_file: str, \n    model: str = \"en-US-Studio-Q\",\n    pitch: float = -20,\n    speaking_rate: float = 0.8,\n    max_retries: int = 5, \n    base_delay: float = 1.0\n):\n    \"\"\"\n    Convert text to speech and save the output as an MP3 file, with exponential backoff for retries.\n    \n    Args:\n        text (str): The text to convert to speech.\n        output_file (str): The path to save the output MP3 file.\n        model (str): The model used.\n        pitch (float): The pitch parameter of the model.\n        speaking_rate (float): The speaking_rate parameter of the model. \n        max_retries (int): Maximum number of retries on failure.\n        base_delay (float): Base delay in seconds for exponential backoff.\n    \"\"\"\n    client = texttospeech.TextToSpeechClient()\n\n    synthesis_input = texttospeech.SynthesisInput(text=text)\n\n    voice = texttospeech.VoiceSelectionParams(\n        language_code=model[:5],\n        name=model\n    )\n\n    audio_config = texttospeech.AudioConfig(\n        audio_encoding=texttospeech.AudioEncoding.MP3,\n        pitch=pitch,\n        speaking_rate=speaking_rate\n    )\n\n    retries = 0\n    while retries < max_retries:\n        try:\n            response = client.synthesize_speech(\n                input=synthesis_input,\n                voice=voice,\n                audio_config=audio_config\n            )\n            with open(output_file, \"wb\") as out:\n                out.write(response.audio_content)\n                print(f\"Audio content written to file: {output_file}\")\n            return\n        except Exception as e:\n            if hasattr(e, 'code') and e.code == 500:\n                retries += 1\n                delay = base_delay * (2 ** (retries - 1))\n                print(f\"Error 500: Retrying in {delay:.2f} seconds... (Attempt {retries}/{max_retries})\")\n                time.sleep(delay)\n            else:\n                print(f\"Non-retryable error: {e}\")\n                raise\n\n    print(f\"Failed to process text after {max_retries} retries.\")\n    raise RuntimeError(\"Max retries reached.\")\n```\n:::\n\n\nTo create an audio of the first paragraph of the example chapter and store it locally, you just run:\n\n::: {#6748317c .cell execution_count=7}\n``` {.python .cell-code}\ntext_to_speech(paragraphs[0], \"out/part1.mp3\")\n```\n:::\n\n\n## Process Text \n\nNow that we have the text split into manageable chunks, cleaned them for better text-to-speech conversion, and created a function to interface with Google's API, it’s time to process the parapgrahs and generate MP3 files. The `process_text()` function puts the pieces from above together and stores MP3 files for each paragraph separately.\n\n::: {#a2f34c58 .cell execution_count=8}\n``` {.python .cell-code}\ndef process_text(text: list, output_folder: str):\n    \"\"\"\n    Process a text, split it into chunks, and generate MP3 files in the output folder.\n\n    Args:\n        text (str): A list of file paths to text files.\n        output_folder (str): The folder to save the generated MP3 files.\n    \"\"\"\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    text_chunks = split_text_by_paragraphs(text)\n\n    for i, chunk in enumerate(text_chunks):\n        output_file_name = f\"part{i+1}.mp3\"\n        output_file_path = os.path.join(output_folder, output_file_name)\n                \n        cleaned_chunk = clean_chunk(chunk)\n\n        text_to_speech(cleaned_chunk, output_file_path)\n        time.sleep(1)\n```\n:::\n\n\nTo create audio files for each paragraph separately, just run:\n\n::: {#21c37559 .cell execution_count=9}\n``` {.python .cell-code}\nprocess_text(text, \"out\")\n```\n:::\n\n\n## Combine Individual Segments\n\nAfter converting individual text chunks to speech, we need to stitch them together into a cohesive audiobook. This final step uses pydub's AudioSegment to combine the individual MP3 files seamlessly, ensuring smooth transitions between segments. Note that you might have to run `pip install audioop-lts` to make this work. \n\n::: {#4d6647a5 .cell execution_count=10}\n``` {.python .cell-code}\ninput_dir = \"out\"\noutput_dir = \"out\"\n\ndef get_number(filename):\n    return int(filename.replace('part', '').replace('.mp3', ''))\n\nmp3_files = sorted(\n    [file for file in os.listdir(input_dir) if file.endswith(\".mp3\")],\n    key=get_number\n)\n\ncombined_audio = None\nfor file in mp3_files:\n    audio = AudioSegment.from_file(os.path.join(input_dir, file))\n    combined_audio = audio if combined_audio is None else combined_audio + audio\ncombined_audio.export(\"out/chapter1.mp3\", format=\"mp3\", bitrate=\"320k\")\n```\n:::\n\n\nYou can listen to the first chapter of Kafka's The Metamorphosis generated with the Google TTS API here:\n\n\n```{=html}\n<iframe src=\"https://drive.google.com/file/d/1z3s_KN3bvQheAeGMa_5Ri-aDs2iQOsKl/preview\" width=\"100%\" height=\"100\" allow=\"autoplay\"></iframe>\n```\n\n\nCreating audiobooks with Google's Text-to-Speech API is surprisingly straightforward. While the output may not match the nuanced performance of human narrators, it provides a quick and effective way to convert text content into listenable audio. This approach is particularly valuable for, e.g., rapid prototyping of audio content, or creating accessible versions of text materials. When using this system, keep the API costs and rate limits, as well as the importance of proper text processing in mind. \n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}