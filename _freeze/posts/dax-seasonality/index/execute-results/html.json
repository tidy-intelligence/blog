{
  "hash": "f9abf7b10d2526f3d908685e4c2bc8e0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analyzing Seasonality in DAX Returns\"\ndescription: \"Debunking the Halloween indicator for German market returns using R\"\nmetadata:\n  pagetitle: \"Analyzing Seasonality in DAX Returns\"\nauthor: \"Christoph Scheuch\"\ndate: \"2023-11-28\" \nimage: thumbnail.png\n---\n\n\n[Seasonalcharts.de](https://www.seasonalcharts.de/classics_dax.html) claims that stock indices exhibit persistent seasonality that may be exploited through an appropriate trading strategy. As part of a job application, I had to replicate the seasonal pattern for the DAX and then test whether this pattern entails a profitable trading strategy. To sum up, I indeed find that a trading strategy that holds the index only over a specific season outperforms the market significantly, but these results might be driven by a few outliers. Note that the post below references an opinion and is for information purposes only. I do not intend to provide any investment advice.\n\nThe code is structured in a way that allows for a straight-forward replication of the methodology for other indices. The post uses the following packages:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(frenchdata)\nlibrary(scales)\nlibrary(fixest)\n```\n:::\n\n\n## Data Preparation\n\nFirst, download data from yahoo finance using the `tidyquant` package. Note that the DAX was officially launched in July 1988, so this is where our sample starts.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_raw <- tq_get(\n  \"^GDAXI\", get = \"stock.prices\", \n  from = \"1988-07-01\", to = \"2023-10-30\"\n) \n```\n:::\n\n\nThen, select only date and the adjusted price (i.e., closing price after adjustments for all applicable splits and dividend distributions) as the relevant variables and compute summary statistics to check for missing or weird values. The results are virtually the same if we use unadjusted closing prices.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax <- dax_raw |>\n  select(date, price = adjusted)\n```\n:::\n\n\nWe replace the missing values by the last available index value.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax <- dax |>\n  arrange(date) |>\n  fill(price, .direction = \"down\")\n```\n:::\n\n\nAs a immediate plausibility check, we plot the DAX over the whole sample period.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax |>\n  ggplot(aes(x = date, y = price)) +\n  geom_line() + \n  labs(x = NULL, y = \"Adjusted Price\",\n       title = \"Adjusted DAX index price between 1988 and 2023\") +\n  scale_y_continuous(labels = scales::comma)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=2100}\n:::\n:::\n\n\nThe main idea of Seasonalcharts is to implement the strategy proposed by [Jacobsen and Bouman (2002)](https://www.jstor.org/stable/3083268?seq=1#metadata_info_tab_contents) and [Jacobsen and Zhan (2018)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2154873) which they label 'The Halloween Indicator' (or 'Sell in May Effect'). The main finding of these papers is that stock indices returns seem significantly lower during the May-October period than during the remainder of the year. The corresponding trading strategy holds an index during the months November-April, but holds the risk-free asset in the May-October period.\n\nTo replicate their approach (and avoid noise in the daily data), we focus on monthly returns from now on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_monthly <- dax |>\n  mutate(year = year(date),\n         month = factor(month(date))) |>\n  group_by(year, month) |>\n  filter(date == max(date)) |>\n  ungroup() |>\n  arrange(date) |>\n  mutate(ret = price / lag(price) - 1) |>\n  drop_na()\n```\n:::\n\n\nAnd as usual in empirical asset pricing, we do not care about raw returns, but returns in excess of the risk-free asset. We simply add the European risk free rate from the Fama-French data library as the corresponding reference point. Of course, one could use other measures for the risk-free rate, but the impact on the results won’t be substantial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfactors_ff3_monthly_raw <- download_french_data(\"Fama/French 3 Factors\")\n\nrisk_free_monthly <- factors_ff3_monthly_raw$subsets$data[[1]] |>\n  mutate(\n    year = year(ymd(str_c(date, \"01\"))),\n    month = factor(month(ymd(str_c(date, \"01\")))),\n    rf = as.numeric(RF) / 100,\n    .keep = \"none\"\n  )\n\ndax_monthly <- dax_monthly |> \n  left_join(risk_free_monthly, join_by(year, month)) |> \n  mutate(ret_excess = ret - rf) |> \n  drop_na()\n```\n:::\n\n\n## Graphical Evidence for Seasonality\n\nWe start by first plotting the average returns for each month. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_monthly |> \n  group_by(month) |> \n  summarize(ret = mean(ret)) |> \n  ggplot(aes(x = month, y = ret, fill = ret > 0)) +\n  geom_col() +\n  scale_y_continuous(labels = percent) + \n  labs(\n    x = \"Month\", y = \"Average DAX Return\", \n    title = \"Average monthly DAX returns between 1988 and 2023\"\n  ) +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=2100}\n:::\n:::\n\n\nThe figure shows negative returns for June, August, and September, while all other months exhibit positive returns. However, it makes more sense to look at distributions instead of simple means, which might be heavily influenced by outliers. To illustrate distributions, I follow [Cedric Scherer](https://www.cedricscherer.com/2021/06/06/visualizing-distributions-with-raincloud-plots-and-how-to-create-them-with-ggplot2/) and use raincloud plots. which combine halved violin plot, a box plot, and the raw data as some kind of scatter. These plots hence provide detailed visualizations of the distributions. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_monthly |> \n  ggplot(aes(x = month, y = ret, group = month)) + \n  ggdist::stat_halfeye(\n    adjust = .5, width = .6, .width = 0, justification = -.3, point_colour = NA\n    ) + \n  geom_boxplot(\n    width = .25, outlier.shape = NA\n    ) +\n  stat_summary(\n    fun = mean, geom=\"point\", color = \"red\", fill = \"red\"\n    ) +\n  geom_point(\n    size = 1.5, alpha = .2, position = position_jitter(seed = 42, width = .1)\n    ) +\n  geom_hline(aes(yintercept = 0), linetype = \"dashed\") +\n  labs(\n    x = \"Month\", y = \"DAX Return\", \n    title = \"Distributions of monthly DAX returns between 1988 and 2023\",\n    subtitle = \"Red dots indicate means, solid lines indicate medians\"\n  ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=2100}\n:::\n:::\n\n\nThe figure suggests that August and September exhibit considerable negative outliers. \n\n## Evaluating Trading Strategies\n\nLet us now take a look at the average excess returns per month. We also add the standard deviation, 5% and 95% quantiles, and t-statistic of a t-test of the null hypothesis that average returns are zero in a given month.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_monthly |>\n  drop_na(ret_excess) |> \n  group_by(Month = month) |>\n  summarize(\n    Mean = mean(ret_excess),\n    SD = sd(ret_excess),\n    Q05 = quantile(ret_excess, 0.05),\n    Q95 = quantile(ret_excess, 0.95),\n    `t-Statistic` = sqrt(n()) * mean(ret_excess) / sd(ret_excess)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 6\n   Month     Mean     SD     Q05    Q95 `t-Statistic`\n   <fct>    <dbl>  <dbl>   <dbl>  <dbl>         <dbl>\n 1 1      0.00621 0.0552 -0.0911 0.0868         0.666\n 2 2      0.00200 0.0541 -0.0868 0.0775         0.219\n 3 3      0.00486 0.0539 -0.0732 0.0842         0.533\n 4 4      0.0260  0.0599 -0.0502 0.119          2.57 \n 5 5      0.00470 0.0401 -0.0573 0.0610         0.693\n 6 6     -0.00353 0.0476 -0.0934 0.0587        -0.439\n 7 7      0.0131  0.0598 -0.0658 0.0902         1.29 \n 8 8     -0.0235  0.0622 -0.168  0.0347        -2.27 \n 9 9     -0.0244  0.0730 -0.176  0.0613        -2.01 \n10 10     0.0206  0.0658 -0.0964 0.122          1.85 \n11 11     0.0228  0.0483 -0.0455 0.0862         2.79 \n12 12     0.0195  0.0554 -0.0586 0.108          2.08 \n```\n\n\n:::\n:::\n\n\nAugust and September seem to usually exhibit negative excess returns with an average of about -2.4% (statistically significant) over all years, while April is the only months that tend to exhibit statistically significant positive excess returns.\n\nLet us proceed to test for the presence of statistically significant excess returns due to seasonal patterns. In the above table, I only test for significance for each month separately. To test for positive returns in a joint model, I regress the monthly excess returns on month indicators. Note that I always adjust the standard errors to be heteroskedasticity robust.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_monthly <- feols(\n  ret_excess ~ month, \n  data = dax_monthly,\n  vcov = \"hetero\"\n)\nsummary(model_monthly)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOLS estimation, Dep. Var.: ret_excess\nObservations: 422 \nStandard-errors: Heteroskedasticity-robust \n             Estimate Std. Error   t value Pr(>|t|)    \n(Intercept)  0.006214   0.009332  0.665913 0.505841    \nmonth2      -0.004210   0.013064 -0.322287 0.747400    \nmonth3      -0.001355   0.013046 -0.103898 0.917301    \nmonth4       0.019820   0.013763  1.440120 0.150597    \nmonth5      -0.001516   0.011534 -0.131452 0.895482    \nmonth6      -0.009744   0.012318 -0.791021 0.429389    \nmonth7       0.006857   0.013752  0.498587 0.618337    \nmonth8      -0.029730   0.013951 -2.131045 0.033680 *  \nmonth9      -0.030625   0.015334 -1.997154 0.046469 *  \nmonth10      0.014389   0.014524  0.990694 0.322419    \nmonth11      0.016551   0.012399  1.334841 0.182669    \nmonth12      0.013261   0.013225  1.002767 0.316565    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 0.056141   Adj. R2: 0.050201\n```\n\n\n:::\n:::\n\n\nSeems like August and September have on average indeed lower returns than January (which is the omitted reference point in this regression). Note that the size of the coefficients from the regression are the same as in the table above (i.e., constant plus coefficient), but the t-statistics are different because we are estimating a joint model now.\n\nAs the raincloud plots indicated that outliers might drive any statistical significant differences, we estimate the model again after trimming the data. In particular, we drop the top and bottom 1% of observations. This trimming step only drops 10 observations. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nret_excess_q01 <- quantile(dax_monthly$ret_excess, 0.01)\nret_excess_q99 <- quantile(dax_monthly$ret_excess, 0.99)\n\nmodel_monthly_trimmed <- feols(\n  ret_excess ~ month, \n  data = dax_monthly |> \n     filter(ret_excess >= ret_excess_q01 & ret_excess <= ret_excess_q99),\n  vcov = \"hetero\"\n)\n   \netable(model_monthly, model_monthly_trimmed, coefstat = \"tstat\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                    model_monthly model_monthly_t..\nDependent Var.:        ret_excess        ret_excess\n                                                   \nConstant          0.0062 (0.6659)   0.0062 (0.6657)\nmonth2          -0.0042 (-0.3223) -0.0042 (-0.3222)\nmonth3          -0.0014 (-0.1039) -0.0014 (-0.1039)\nmonth4             0.0198 (1.440)   0.0099 (0.8135)\nmonth5          -0.0015 (-0.1315) -0.0015 (-0.1314)\nmonth6          -0.0097 (-0.7910) -0.0097 (-0.7907)\nmonth7            0.0069 (0.4986)   0.0024 (0.1805)\nmonth8          -0.0297* (-2.131)  -0.0201 (-1.602)\nmonth9          -0.0306* (-1.997)  -0.0142 (-1.127)\nmonth10           0.0144 (0.9907)   0.0144 (0.9903)\nmonth11            0.0165 (1.335)    0.0128 (1.071)\nmonth12            0.0133 (1.003)   0.0087 (0.6897)\n_______________ _________________ _________________\nVCOV type       Heteroskeda.-rob. Heteroskeda.-rob.\nObservations                  422               412\nR2                        0.07502           0.03994\nAdj. R2                   0.05020           0.01354\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nIndeed, now no month exhibits a statistically significant outperformance compared to January. \n\nNext, I follow Jacobsen and Bouman (2002) and simply regress excess returns on dummies that indicate specific seasons, i.e., I estimate the model \n\n$$ y_t=\\alpha + \\beta D_t + \\epsilon_t,$$ \n\nwhere $D_t$ is a dummy variable equal to one for the months in a specific season and zero otherwise. We consider both the 'Halloween' season (where the dummy is one for November-April). If $D_t$ is statistically significant and positive for the corresponding season, then we take this as evidence for the presence of seasonality effects.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhalloween_months <- c(11, 12, 1, 2, 3, 4)\n\ndax_monthly <- dax_monthly |>\n  mutate(halloween = if_else(month %in% halloween_months, 1L, 0L))\n```\n:::\n\n\nWe again estimate two models to analyze the 'Halloween' effect:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_halloween <- feols(\n  ret_excess ~ halloween, \n  data = dax_monthly,\n  vcov = \"hetero\"\n)\n\nmodel_halloween_trimmed <- feols(\n  ret_excess ~ halloween, \n  data = dax_monthly |> \n     filter(ret_excess >= ret_excess_q01 & ret_excess <= ret_excess_q99),\n  vcov = \"hetero\"\n)\n\netable(model_halloween, model_halloween_trimmed, coefstat = \"tstat\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  model_halloween model_hallowe..\nDependent Var.:        ret_excess      ret_excess\n                                                 \nConstant        -0.0024 (-0.5698) 0.0016 (0.4271)\nhalloween        0.0159** (2.827) 0.0088. (1.754)\n_______________ _________________ _______________\nVCOV type       Heteroskeda.-rob. Heteroske.-rob.\nObservations                  422             412\nR2                        0.01865         0.00745\nAdj. R2                   0.01632         0.00503\n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\nWe indeed find evidence that excess returns are higher during the months November-April relative to the remaining months in the full sample. However, if we remove the top and bottom 1% of observations, then the statistical significant outperformance disappears again. \n\nAs a last step, let us compare three different strategies: (i) buy and hold the index over the full year, (ii) go long in the index outside of the Halloween season and otherwise hold the risk-free asset, and (iii) go long in the index outside of the Halloween season and otherwise short the index. Below I compare the returns of the three different strategies on an annual basis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndax_monthly <- dax_monthly |>\n  mutate(\n    ret_excess_halloween = if_else(halloween == 1, ret_excess, 0),\n    ret_excess_halloween_short = if_else(halloween == 1, ret_excess, -ret_excess)\n  )\n```\n:::\n\n\nWhich of these strategies might constitute a better investment opportunity? For a very simple assessment, let us compute the corresponding Sharpe ratios. Note that I annualize Sharpe ratios by multiplying them with $\\sqrt{12}$ which strictly speaking only works under IID distributed returns (which is typically unlikely to be the case), but which suffices for the purpose of this post.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsharpe_ratio <- function(x) {\n  sqrt(12) *  mean(x) / sd(x)\n}\n\nbind_rows(\n  dax_monthly |>\n    summarize(\n      `Buy and Hold` = sharpe_ratio(ret),\n      `Halloween` = sharpe_ratio(ret_excess_halloween),\n      `Halloween-Short` = sharpe_ratio(ret_excess_halloween_short)\n    ) |> \n    mutate(Data = \"Full\"),\n  dax_monthly |> \n    filter(ret_excess >= ret_excess_q01 & ret_excess <= ret_excess_q99) |>\n    summarize(\n      `Buy and Hold` = sharpe_ratio(ret_excess),\n      `Halloween` = sharpe_ratio(ret_excess_halloween),\n      `Halloween-Short` = sharpe_ratio(ret_excess_halloween_short)\n    ) |> \n    mutate(Data = \"Trimmed\")\n) |> \n  select(Data, everything())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  Data    `Buy and Hold` Halloween `Halloween-Short`\n  <chr>            <dbl>     <dbl>             <dbl>\n1 Full             0.465     0.597             0.473\n2 Trimmed          0.403     0.503             0.298\n```\n\n\n:::\n:::\n\n\nThe Sharpe ratio suggests that the Halloween strategy is a better investment opportunity than the other strategies for both the full and the trimmed sample. Shorting the market in the Halloween season even leads to worse performance than just staying invested in the market the whole time once we drop the outliers. \n\nTo sum up, this post showed some simple data-related issues that we should consider when we analyze return data. Overall, we could find strong support for this seasonality effect from a statistical perspective once we get rid of a few extreme observations.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}