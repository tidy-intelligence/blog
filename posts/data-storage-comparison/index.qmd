---
title: "Tidy Data: Tabular Data Storage Comparison"
description: "A comparison of popular open-source data storage technologies using R, Python, and Julia."
metadata:
  pagetitle: "Tidy Data: Tabular Data Storage Comparison"
author: "Christoph Scheuch"
date: "2024-01-19" 
image: thumbnail.png
image-alt: A server room with a more subdued and professional atmosphere. It features four different database servers, each representing a distinct tabular data storage technology. The first server has a sleek and efficient design, symbolizing a modern, high-performance database. The second server is sturdy and straightforward, indicative of a traditional, reliable database system. The third server is compact and practical, representing an efficient, resource-conserving database. The fourth is advanced yet unobtrusive, suggesting a sophisticated, AI-powered database. The room has soft lighting, with a focus on functionality and neatness. The overall ambiance is more business-like and less flashy, conveying a sense of serious technology at work. Created with DALL-E 3.
draft: true
---

# Create example data

```{r}
library(tidyverse)

data <- tibble(
  character_column = c("A", "B", "C", "D"), 
  date_column = as.Date(c("2023-01-01", "2023-02-01", "2023-03-01", "2023-04-01")),
  datetime_column = ymd_hms(c("2023-01-01 10:00:00", "2023-02-01 11:00:00", 
                              "2023-03-01 12:00:00", "2023-04-01 13:00:00")),
  numeric_column = c(1.5, 2.5, 3.5, 4.5),
  integer_column = as.integer(c(1, 2, 3, 4)),
  logical_column = c(TRUE, FALSE, FALSE, TRUE)
)
```

# CSV

Simple, widely supported, and easy to read and write in R, Python, and Julia.

Not efficient for large datasets and doesn't support complex data structures or metadata well.

```{r}
#| message: false
write_csv(data, file = "data.csv")
data_csv <- read_csv("data.csv")

data_csv |> 
  glimpse()
```

# SQLite

Lightweight, file-based SQL database. Easy to use and supported by R, Python, and Julia without the need for a separate server.

Not suitable for very large or high-concurrency applications.

```{r}
library(RSQLite)

con_sqlite <- dbConnect(SQLite(), "data.sqlite")

copy_to(con_sqlite, data, "data", overwrite = TRUE)
data_sqlite <- tbl(con_sqlite, "data") |> 
  collect()

data_sqlite |> 
  glimpse()
```


# DuckDB

https://r4ds.hadley.nz/databases

DuckDB is an emerging database management system that's gaining attention for its efficiency and ease of use, particularly in the data science community. It's designed to be an OLAP (Online Analytical Processing) database and is especially well-suited for analytical queries on large datasets.

As a relatively new system, it might not have the same level of community support, tools, and integrations as more established databases.

```{r}
#| warning: false
library(duckdb)

con_duckdb <- dbConnect(duckdb(), "data.duckdb")

copy_to(con_duckdb, data, "data", overwrite = TRUE)
data_duckdb <- tbl(con_duckdb, "data") |> 
  collect()

data_duckdb |> 
  glimpse()
```

# Parquet

https://r4ds.hadley.nz/arrow

Columnar storage format, which is great for analytics and large datasets. Offers efficient data compression and encoding schemes.

Requires additional libraries and understanding of its format.

```{r}
library(arrow)

write_parquet(data, "data.parquet")
data_parquet <- read_parquet("data.parquet")

data_parquet |> 
  glimpse()
```

# Conclusion

...
