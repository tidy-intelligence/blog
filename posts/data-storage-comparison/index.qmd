---
title: "Tidy Data: Tabular Data Storage Comparison"
description: "A comparison of popular open-source data storage technologies using R, Python, and Julia."
metadata:
  pagetitle: "Tidy Data: Tabular Data Storage Comparison"
author: "Christoph Scheuch"
date: "2024-01-19" 
image: thumbnail.png
image-alt: A server room with a more subdued and professional atmosphere. It features four different database servers, each representing a distinct tabular data storage technology. The first server has a sleek and efficient design, symbolizing a modern, high-performance database. The second server is sturdy and straightforward, indicative of a traditional, reliable database system. The third server is compact and practical, representing an efficient, resource-conserving database. The fourth is advanced yet unobtrusive, suggesting a sophisticated, AI-powered database. The room has soft lighting, with a focus on functionality and neatness. The overall ambiance is more business-like and less flashy, conveying a sense of serious technology at work. Created with DALL-E 3.
draft: true
---

```{r}
#| echo: false
JuliaCall::julia_setup("/Applications/Julia-1.9.app/Contents/Resources/julia/bin/")
```

# Create example data

::: {.panel-tabset}
### R
```{r}
#| message: false
library(tidyverse)

data <- tibble(
  character_column = c("A", "B", "C", "D"), 
  date_column = as.Date(c("2023-01-01", "2023-02-01", "2023-03-01", "2023-04-01")),
  datetime_column = ymd_hms(c("2023-01-01 10:00:00", "2023-02-01 11:00:00", "2023-03-01 12:00:00", "2023-04-01 13:00:00")),
  numeric_column = c(1.5, 2.5, 3.5, 4.5),
  integer_column = as.integer(c(1, 2, 3, 4)),
  logical_column = c(TRUE, FALSE, FALSE, TRUE)
)

glimpse(data)
```
### Python
```{python}
import pandas as pd

data = pd.DataFrame({
  "character_column": ["A", "B", "C", "D"],
  "date_column": pd.to_datetime(["2023-01-01", "2023-02-01", "2023-03-01", "2023-04-01"]).date,
  "datetime_column": pd.to_datetime(["2023-01-01 10:00:00", "2023-02-01 11:00:00", "2023-03-01 12:00:00", "2023-04-01 13:00:00"]),
  "numeric_column": [1.5, 2.5, 3.5, 4.5],
  "integer_column": [1, 2, 3, 4],
  "logical_column": [True, False, False, True]
})

data.info()
```
### Julia
```{julia}
using DataFrames, Dates

data = DataFrame(
  character_column = ["A", "B", "C", "D"],
  date_column = Date.(["2023-01-01", "2023-02-01", "2023-03-01", "2023-04-01"]),
  datetime_column = DateTime.(["2023-01-01T10:00:00", "2023-02-01T11:00:00", "2023-03-01T12:00:00", "2023-04-01T13:00:00"]),
  numeric_column = [1.5, 2.5, 3.5, 4.5],
  integer_column = Int32.([1, 2, 3, 4]),
  logical_column = [true, false, false, true]
);

function get_column_types(df::DataFrame)
  return DataFrame(
    Column_Name = names(df),
    Column_Type = eltype.(eachcol(df))
  )
end;

get_column_types(data)
```
:::

# CSV

Simple, widely supported, and easy to read and write in R, Python, and Julia.

Not efficient for large datasets and doesn't support complex data structures or metadata well.

::: {.panel-tabset}
### R
```{r}
#| message: false
library(readr)

write_csv(data, file = "data_r.csv")
data_csv <- read_csv("data_r.csv")

glimpse(data_csv)
```

### Python
```{python}
data.to_csv("data_python.csv", index = False)
data_csv = pd.read_csv("data_python.csv")

data_csv.info()
```

### Julia
```{julia}
using CSV

CSV.write("data_julia.csv", data);
data_csv = CSV.read("data_julia.csv", DataFrame);

get_column_types(data_csv)
```


:::

# SQLite

Lightweight, file-based SQL database. Easy to use and supported by R, Python, and Julia without the need for a separate server.

Not suitable for very large or high-concurrency applications.

::: {.panel-tabset}
### R
```{r}
library(RSQLite)

con_sqlite <- dbConnect(SQLite(), "data_r.sqlite")

copy_to(con_sqlite, data, "data", overwrite = TRUE)
data_sqlite <- tbl(con_sqlite, "data") |> 
  collect()

glimpse(data_sqlite)
```

### Python
```{python}
import sqlite3

con_sqlite = sqlite3.connect(database = "data_python.sqlite")

data.to_sql("data", con_sqlite, if_exists = "replace", index = False)

data_sqlite = pd.read_sql_query("SELECT * FROM data", con_sqlite)

data_sqlite.info()
```

### Julia

```{julia}
using SQLite

con_sqlite = SQLite.DB("data_julia.sqlite");

SQLite.load!(data, con_sqlite, "data", replace = true);

data_sqlite = DBInterface.execute(con_sqlite, "SELECT * FROM data") |> DataFrame;

get_column_types(data_sqlite)
```

:::

# DuckDB

https://r4ds.hadley.nz/databases

DuckDB is an emerging database management system that's gaining attention for its efficiency and ease of use, particularly in the data science community. It's designed to be an OLAP (Online Analytical Processing) database and is especially well-suited for analytical queries on large datasets.

As a relatively new system, it might not have the same level of community support, tools, and integrations as more established databases.

::: {.panel-tabset}
### R
```{r}
#| warning: false
library(duckdb)

con_duckdb <- dbConnect(duckdb(), "data_r.duckdb")

copy_to(con_duckdb, data, "data", overwrite = TRUE)
data_duckdb <- tbl(con_duckdb, "data") |> 
  collect()

glimpse(data_duckdb)
```

### Python
```{python}
#| warning: false
import duckdb

con_duckdb = duckdb.connect("data_r.duckdb")

data.to_sql("data", con_duckdb, if_exists = "replace", index = False)

data_duckdb = pd.read_sql_query("SELECT * FROM data", con_duckdb)

data_duckdb.info()
```

### Julia
```{julia}
using DuckDB

con_duckdb = DBInterface.connect(DuckDB.DB, "data_julia.duckdb");

# ...
```

:::

# Parquet

https://r4ds.hadley.nz/arrow

Columnar storage format, which is great for analytics and large datasets. Offers efficient data compression and encoding schemes.

Requires additional libraries and understanding of its format.

::: {.panel-tabset}
### R
```{r}
#| message: false
library(arrow)

write_parquet(data, "data_r.parquet")
data_parquet <- read_parquet("data_r.parquet")

glimpse(data_parquet)
```

### Python
```{python}
import pyarrow.parquet as pq

data.to_parquet("data_python.parquet")
data_parquet = pd.read_parquet("data_python.parquet")

data_parquet.info()
```

### Julia
```{julia}
using Arrow

Arrow.write("data_julia.parquet", data);

data_parquet = Arrow.Table("data_julia.parquet") |> DataFrame;

get_column_types(data_parquet)
```

:::

# Conclusion

...
