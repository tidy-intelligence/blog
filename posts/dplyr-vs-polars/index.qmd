---
title: "Tidy Data Manipulation: dplyr vs polars"
description: "A comparison of R's dplyr and Python's polars data manipulation packages"
metadata:
  pagetitle: "Tidy Data Manipulation: dplyr vs polars"
author: "Christoph Scheuch"
date: "2024-01-02" 
image: thumbnail.png
image-alt: A realistic polar bear sitting on a snowy landscape, looking curiously at a pair of pliers lying on the ground. The polar bear should have a thick, white coat and appear both majestic and inquisitive. The pliers are standard steel with red rubber grips, contrasting against the white snow. The scene is set in the Arctic with a clear blue sky and a few distant icebergs in the background. Created with DALL-E 3.
---

There are a myriad of options to perform essential data manipulation tasks in R and Python (see, for instance, my other posts on [dplyr vs ibis](../dplyr-vs-ibis/index.qmd) and [dplyr vs pandas](../dplyr-vs-pandas/index.qmd)). However, if we want to do tidy data science in R, there is a clear forerunner: `dplyr`. In the world of Python, `polars` is a relatively new kid on the block that shares a lot of semantic with `dplyr`. In this blog post, I illustrate their syntactic similarities and highlight differences between these two packages that emerge for a few key tasks. 

Before we dive into the comparison, a short introduction to the packages: the `dplyr` package in R allows users to refer to columns without quotation marks due to its implementation of non-standard evaluation (NSE). NSE is a programming technique used in R that allows functions to capture the expressions passed to them as arguments, rather than just the values of those arguments. The primary goal of NSE in the context of `dplyr` is to create a more user-friendly and intuitive syntax. This makes data manipulation tasks more straightforward and aligns with the general philosophy of the `tidyverse` to make data science faster, easier, and more fun.[^1]

`polars` is also designed for data manipulation and heavily optimized for performance, but there are significant differences in their approach, especially in how they handle column referencing and expression evaluation. Python generally relies on standard evaluation, meaning expressions are evaluated to their values before being passed to a function. In `polars`, column references typically need to be explicitly stated, often using quoted names or through methods attached to data frame objects.

# Loading packages

We start by loading the main packages of interest and the popular `palmerpenguins` package that exists for both R and Python. We then use the `penguins` data frame as the data to compare all functions and methods below. Note that we also limit the print output of `polars` data frames to 10 rows to prevent this post being flooded by excessively long tables. 

::: {.panel-tabset}
## R
```{r}
#| message: false
library(dplyr)
library(palmerpenguins)

penguins <- palmerpenguins::penguins
```
## Python
```{python}
#| message: false
import polars as pl
from palmerpenguins import load_penguins

pl.Config(tbl_rows = 10)

penguins = load_penguins().pipe(pl.from_pandas)
```
:::

# Work with rows

## Filter rows

Filtering rows works very similarly for both packages, they even have the same function names: `dplyr::filter()` and `polars.filter()`. To select columns in `polars`, you need the `polars.col()` selector. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  filter(species == "Adelie" & 
           island %in% c("Biscoe", "Dream"))
```
### Python
```{python}
(penguins
  .filter(
    (pl.col("species") == "Adelie") & 
    (pl.col("island").is_in(["Biscoe", "Dream"]))) 
)
```
:::

## Slice rows

`dplyr::slice()` takes integers with row numbers as inputs, so you can use ranges and arbitrary vectors of integers. `polars.slice()` only takes the start index and the length of the slice as inputs. For instance, to the the same result of slicing rows 10 to 20, the code looks as follows (note that indexing starts at 0 in Python, while it starts at 1 in R):

::: {.panel-tabset}
### R
```{r}
penguins |> 
  slice(10:20)
```
### Python
```{python}
(penguins
  .slice(9, 11)  
)
```
:::

## Arrange rows

To orders the rows of a data frame by the values of selected columns, we have `dplyr::arrange()` and `polars.sort()`. Note that `dplyr::arrange()` arranges rows in an an ascending order and puts `NA` values last. `polars.sort()`, on the other hand, arranges rows in an ascending order and starts with `null` as default. Note that there are options to control these defaults. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  arrange(island, -bill_length_mm)
```
### Python
```{python}
(penguins
  .sort(["island", "bill_length_mm"], 
        descending=[False, True], nulls_last=True)
)
```
:::

# Work with columns

## Select columns

Selecting a subset of columns works essentially the same for both and `dplyr::select()` and `polars.select()` even have the same name. Note that you don't have to use `polars.col()` but can just pass strings in the `polars.select()` method. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  select(bill_length_mm, sex)
```
### Python
```{python}
(penguins
  .select(pl.col("bill_length_mm"), pl.col("sex"))
)
```
:::

## Rename columns

Renaming columns also works very similarly with the major difference that `polars.rename()` takes a dictionary with mappings of old to new names as input, while `dplyr::rename()` takes variable names via the usual NSE.

::: {.panel-tabset}
### R
```{r}
penguins |> 
  rename(bill_length = bill_length_mm,
         bill_depth = bill_depth_mm)
```
### Python
```{python}
(penguins
  .rename({"bill_length_mm": "bill_length",
           "bill_depth_mm" : "bill_depth"})
)
```
:::

## Mutate columns

Transforming existing columns or creating new ones is an essential part of data analysis. `dplyr::mutate()` and `polars.with_columns()` are the work horses for these tasks. While `dplyr` starts with column names before the expressions that transform columns, `polars` uses the `polars.alias()` method to assign expressions to new columns.

::: {.panel-tabset}
### R
```{r}
penguins |> 
  mutate(ones = 1,
         bill_length = bill_length_mm / 10,
         bill_length_squared = bill_length^2) |> 
  select(ones, bill_length_mm, bill_length, bill_length_squared)
```
### Python
```{python}
(penguins 
  .with_columns(pl.lit(1).alias("ones"),
                (pl.col("bill_length_mm") / 10).alias("bill_length"))
  .with_columns((pl.col("bill_length") ** 2).alias("bill_length_squared"))
  .select(pl.col("ones"), pl.col("bill_length_mm"),  
          pl.col("bill_length"), pl.col("bill_length_squared"))
)
```
:::

## Relocate columns

`dplyr::relocate()` provides options to change the positions of columns in a data frame, using the same syntax as `dplyr::select()`. In addition, there are the options `.after` and `.before` to provide users with additional shortcuts. 

The recommended way to relocate columns in `polars` is to use the `polars.select()` method, but there are no options as in `dplyr::relocate()`. In fact, the safest way to consistently get the correct order of columns is to explicitly specify them. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  relocate(c(species, bill_length_mm), .before = year)
```
### Python
```{python}
(penguins
  .select(pl.col("island"), pl.col("bill_depth_mm"), 
          pl.col("flipper_length_mm"), pl.col("body_mass_g"), pl.col("sex"), 
          pl.col("species"), pl.col("bill_length_mm"), pl.col("year"))
)
```
:::

# Work with groups of rows

## Simple summaries by group

Let's suppose we want to compute summaries by groups such as means or medians. Both packages are very similar again: on the R side you have `dplyr::group_by()` and `dplyr::summarize()`, while on the Python side you have `polars.group_by()` and `polars.agg()`. 

Note that `dplyr::group_by()` also automatically arranges the results by the group, so the reproduce the results of `dplyr`, we need to add `polars.sort()` to the chain. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  group_by(island) |> 
  summarize(bill_depth_mean = mean(bill_depth_mm, na.rm = TRUE))
```
### Python
```{python}
(penguins
  .group_by("island")
  .agg([pl.mean("bill_depth_mm").alias("bill_depth_mean")])
  .sort("island")
)
```
:::

## More complicated summaries by group

Typically, you want to create multiple different summaries by groups. `dplyr` provides a lot of flexibility to create new variables on the fly, while `polars` seems to be a bit more restrictive. For instance, to compute the share of female penguins by group, it makes more sense to create an `Ã¬s_female` indicator column using `polars` because `polars.mean()` does not accept expressions as inputs. 

::: {.panel-tabset}
### R
```{r}
penguins |> 
  group_by(island) |> 
  summarize(count = n(),
            bill_depth_mean = mean(bill_depth_mm, na.rm = TRUE),
            flipper_length_median = median(flipper_length_mm, na.rm = TRUE),
            body_mass_sd = sd(body_mass_g, na.rm = TRUE),
            share_female = mean(sex == "female", na.rm = TRUE))
```
### Python
```{python}
(penguins
  .with_columns((pl.when(pl.col("sex") == "female").then(1)
                  .when(pl.col("sex").is_null()).then(None)
                  .otherwise(0)).alias("is_female"))
  .group_by("island")
  .agg([
    pl.count().alias("count"),
    pl.mean("bill_depth_mm").alias("bill_depth_mean"),
    pl.median("flipper_length_mm").alias("flipper_length_median"),
    pl.std("body_mass_g").alias("body_mass_sd"),
    pl.mean("is_female").alias("share_female")
  ])
  .sort("island")
)
```
:::

## Conclusion

This post highlights syntactic similarities and differences across R's `dplyr` and Python's `polars` packages. Two key points emerge: (i) `dplyr` heavily relies on NSE to enable a syntax that refrains from using strings and column selectors, something that is not possible in Python; (ii) creating new variables in `dplyr` is read from left to right (the new variable name comes first, the definition later), while it is the other way around in `polars` (definition first, new variable name later). I want to close this post by emphasizing that both languages and packages have their own merits and I won't strictly recommend one over the other - maybe in another post :smile:

[^1]: See the unifying principles of the tidyverse: [https://design.tidyverse.org/unifying.html](https://design.tidyverse.org/unifying.html).