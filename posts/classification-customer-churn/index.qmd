---
title: "Tidy Classification Models: Customer Churn Prediction"
description: "A comparison of classification approaches using the tidymodels package"
metadata:
  pagetitle: "Tidy Classification Models"
author: "Christoph Scheuch"
date: "2024-02-22" 
image: thumbnail.png
image-alt: A squirrel sitting in a bright and friendly office, curiously looking at an old-fashioned rotary dial telephone on a wooden desk. Sunlight filters through the window, creating a warm, welcoming atmosphere. The office is decorated with vibrant green plants in terracotta pots and bookshelves filled with colorful books. Created with DALL-E 3.
categories: 
  - R
  - Modeling
draft: true
execute: 
  cache: true
---

...

`tidymodels` is an ecosystem of R packages designed for data modeling and statistical analysis that adheres to the principles of the `tidyverse`. It provides a comprehensive framework for building and evaluating models, streamlining workflows from data preprocessing and feature engineering to model training, validation, and finte-tuning. It also provides a unified interface for various modeling techniques, `tidymodels` simplifies the process of creating reproducible and scalable data analysis pipelines, catering to both novice and experienced data scientists.

...

## Load packages

```{r}
#| message: false
#| warning: false
library(tidymodels)
library(glmnet)
library(ranger)
library(xgboost)
library(torch)
library(brulee)
library(readr)
library(janitor)
library(stringr)
```


## Download & clean data

- We only use 11 observations by dropping all rows with a missing value, so I'm not going into details here. 
- Remove `customer_id` because we don't need it for pre-processing
- Apply one-hot encoding to the remaining variables later

```{r}
#| message: false
#| warning: false
data_url <- "https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv"
customer_raw <- read_csv(data_url) 

customer <- customer_raw |> 
  clean_names() |> 
  select(-customer_id) |> 
  na.omit() |> 
  mutate(churn = factor(if_else(churn=="Yes", 1L, 0L)),
         female = if_else(gender=="Female", 1L, 0L),
         senior_citizen = as.integer(senior_citizen)) |> 
  select(-gender) |> 
  mutate(
    across(c(partner, dependents, phone_service, paperless_billing), 
           ~if_else(. == "Yes", 1L, 0L)),
    across(c(multiple_lines, internet_service, online_security, online_backup, 
             device_protection, tech_support, streaming_tv, streaming_movies,
             contract, paperless_billing, payment_method),
           ~str_to_lower(str_replace_all(., " |\\-", "_")))
    ) 

set.seed(1234)
customer_split <- initial_split(customer, prop = 4/ 5, strata = churn)
customer_folds <- vfold_cv(training(customer_split), v = 5, strata = churn)
```

## Pre-process data

- Standardize all double variables
- One-hot encode all remaining categorical variables
- Important to keep that order, otherwise the encoded variables are also standardized!

```{r}
customer_recipe <- recipe(churn ~ ., data = training(customer_split)) |> 
  step_log(c(total_charges)) |> 
  step_normalize(c(tenure, monthly_charges)) |>
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) 
```

```{r}
customer_workflow <- workflow() |> 
  add_recipe(customer_recipe)
```

## Build models

::: {.panel-tabset}
### Logistic regression
```{r}
spec_logistic <- logistic_reg(penalty = 0.0001, mixture = 1) |>
  set_engine("glmnet") |> 
  set_mode("classification")
```

### Random Forest
```{r}
spec_random_forest <- rand_forest() |>
  set_engine("ranger") |>
  set_mode("classification")
```

### XGBoost
```{r}
spec_xgboost <- boost_tree() |>
  set_engine("xgboost") |>
  set_mode("classification")
```

### K-nearest neighbor
```{r}
spec_knn <- nearest_neighbor(neighbors = 4) |>
  set_engine("kknn") |>
  set_mode("classification")
```

### Neural network
```{r}
spec_neural_net <- mlp(epochs = 500, hidden_units = 10) |>
  set_engine("brulee") |>
  set_mode("classification") 
```

## Fit models on training data

```{r}
create_metrics_training <- function(spec) {
  customer_workflow |> 
    add_model(spec) |> 
    fit_resamples(
      resamples = customer_folds,
      metrics = metric_set(recall, precision, accuracy),
      control = control_resamples(save_pred = TRUE)
    ) |> 
    collect_metrics(summarize = TRUE) |> 
    mutate(model = attributes(spec)$class[1])
}

metrics_training <- list(
  spec_logistic, spec_random_forest, spec_xgboost, 
  spec_knn, spec_neural_net
) |> 
  map_df(create_metrics_training)
```

## Evaluate models

```{r}
metrics_training |> 
  mutate(ci_lower = mean - std_err / sqrt(n) * qnorm(0.99),
         ci_upper = mean + std_err / sqrt(n) * qnorm(0.99)) |> 
  ggplot(aes(x = mean, y = model, fill = model)) +
  geom_col() + 
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = .2,
                position = position_dodge(.9)) +
  facet_wrap(~.metric, ncol = 1) +
  labs(x = NULL, y = NULL,
       title = "Comparison of metrics for different classification models",
       subtitle = "Based on training data") +
  theme_minimal() +
  theme(legend.position = "none") +
  coord_cartesian(xlim = c(0, 1)) 
```

```{r}
create_metrics_test <- function(spec) {

  test_predictions <-  customer_workflow |>
    add_model(spec) |> 
    fit(data =  training(customer_split)) |> 
    predict(new_data = testing(customer_split))
  
  test_results <- bind_cols(testing(customer_split), test_predictions)
  
  bind_rows(
    recall(test_results, truth = churn, estimate = .pred_class),
    precision(test_results, truth = churn, estimate = .pred_class),
    accuracy(test_results, truth = churn, estimate = .pred_class)
  ) |> 
    mutate(model = attributes(spec)$class[1])
}

metrics_test <- list(
  spec_logistic, spec_random_forest, spec_xgboost, 
  spec_knn, spec_neural_net
) |> 
  map_df(create_metrics_test)

metrics <- bind_rows(
  metrics_training |> 
    mutate(sample = "Training") |> 
    select(metric = .metric, estimate = mean, model, sample),
  metrics_test |> 
    mutate(sample = "Test") |> 
    select(metric = .metric, estimate = .estimate, model, sample)
) 

metrics |> 
  ggplot(aes(x = estimate, y = model, fill = sample)) +
  geom_col(position = "dodge") +
  facet_wrap(~metric, ncol = 1) +
  labs(x = NULL, y = NULL, fill = "Sample",
       title = "Comparison of metrics for different classification models",
       subtitle = "Training is the mean across 5-fold cross validation results, Test is based on 20% of the initial data") +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 1)) 
```

## Tune models

::: {.panel-tabset}
### Logistic regression

```{r}
spec_logistic_tune <- logistic_reg(
  penalty = tune(), 
  mixture = tune()
) |>
  set_engine("glmnet") |> 
  set_mode("classification")

grid_logistic <- grid_regular(
  penalty(range = c(-10, 0), trans = log10_trans()),
  mixture(range = c(0, 1)),
  levels = 5 
)

tune_logistic <- tune_grid(
  customer_workflow |> 
    add_model(spec_logistic_tune),
  resamples = customer_folds,
  grid = grid_logistic,
  metrics = metric_set(recall, precision, accuracy) 
)

tuned_model_logistic <- finalize_model(
  spec_logistic_tune, select_best(tune_logistic, "accuracy")
)
tuned_model_logistic
```

### Random forest

```{r}
spec_random_forest_tune <- rand_forest(
  mtry = tune(), 
  min_n = tune()
) |>
  set_engine("ranger") |>
  set_mode("classification")

grid_random_forest <- grid_regular(
  mtry(range = c(1, 5)),
  min_n(range = c(2, 40)),
  levels = 5
)

tune_random_forest  <- tune_grid(
  customer_workflow |> 
    add_model(spec_random_forest_tune),
  resamples = customer_folds,
  grid = grid_random_forest,
  metrics = metric_set(recall, precision, accuracy) 
)

tuned_model_random_forest <- finalize_model(
  spec_random_forest_tune, select_best(tune_random_forest, "accuracy")
)
tuned_model_random_forest
```

### XGBoost

```{r}
spec_xgboost_tune <- boost_tree(
  mtry = tune(), 
  min_n = tune()
) |>
  set_engine("xgboost") |>
  set_mode("classification")

grid_xgboost <- grid_regular(
  mtry(range = c(1L, 5L)),
  min_n(range = c(1L, 40L)),
  levels = 5
)

tune_xgboost  <- tune_grid(
  customer_workflow |> 
    add_model(spec_xgboost_tune),
  resamples = customer_folds,
  grid = grid_xgboost,
  metrics = metric_set(recall, precision, accuracy) 
)

tuned_model_xgboost <- finalize_model(
  spec_xgboost_tune, select_best(tune_xgboost, "accuracy")
)
tuned_model_xgboost
```

### K-nearest neighbor

```{r}
grid_knn <- grid_regular(
  neighbors(range = c(1L, 20L)),
  levels = 5 
)

spec_knn_tune <- nearest_neighbor(
  neighbors = tune()
) |>
  set_engine("kknn") |>
  set_mode("classification")

tune_knn <- tune_grid(
  customer_workflow |> 
    add_model(spec_knn_tune),
  resamples = customer_folds,
  grid = grid_knn,
  metrics = metric_set(recall, precision, accuracy) 
)

tuned_model_knn <- finalize_model(spec_knn_tune, select_best(tune_knn, "accuracy"))
tuned_model_knn
```

### Neural net

```{r}
#| warning: false
#| messag: false
grid_neural_net <- grid_regular(
  hidden_units(range = c(1L, 10L)),
  epochs(range = c(10L, 1000L)),
  levels = 5 
)

spec_neural_net_tune <- mlp(
  epochs = tune(), 
  hidden_units = tune()
) |>
  set_engine("brulee") |>
  set_mode("classification") 

tune_neural_net <- tune_grid(
  customer_workflow |> 
    add_model(spec_neural_net_tune),
  resamples = customer_folds,
  grid = grid_neural_net,
  metrics = metric_set(recall, precision, accuracy) 
)

tuned_model_neural_net <- finalize_model(spec_neural_net_tune, select_best(tune_neural_net, "accuracy"))
tuned_model_neural_net
```

::: 

## Comparing tuned models

```{r}
metrics_tuned <- list(
  tuned_model_logistic, tuned_model_random_forest, tuned_model_xgboost,
  tuned_model_knn, tuned_model_neural_net
) |> 
  map_df(create_metrics_test)

metrics_comparison <- bind_rows(
  metrics,
  metrics_tuned |> 
    mutate(sample = "Tuned") |> 
    select(metric = .metric, estimate = .estimate, model, sample)
)

metrics_comparison |> 
  filter(metric == "accuracy") |> 
  ggplot(aes(x = estimate, y = model, fill = sample)) +
  geom_col(position = "dodge") +
  facet_wrap(~metric, ncol = 1) +
  labs(x = NULL, y = NULL, fill = "Sample",
       title = "Comparison of accuracy for different classification models",
       subtitle = "Training is the mean across 5-fold cross validation results, Test is based on 20% of the initial data") +
  theme_minimal() +
  coord_cartesian(xlim = c(0, 1)) 
```

Which model has on average the best rank? 

```{r}
metrics_comparison |> 
  group_by(sample, metric) |> 
  arrange(-estimate) |> 
  mutate(rank = row_number()) |> 
  group_by(model) |> 
  summarize(rank = mean(rank)) |> 
  arrange(rank)
```

## Concluding remarks

What I love most about `tidymodels` is its scalability with respect to models and metrics. You can quickly prototype different approaches using very little code. 
