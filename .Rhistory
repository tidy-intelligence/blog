title = "How many companies have ESG scores per sector?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
esg_scores_sector|>
pivot_longer(cols = contains("score"))|>
mutate(name = factor(name),
sector = tidytext::reorder_within(sector, -value, name))|>
ggplot(aes(y = sector, x = value, fill = name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~name, scales = "free_y") +
theme_minimal() +
tidytext::scale_y_reordered() +
geom_text(aes(label = round(value, 0)), hjust = 1.1, color = "white") +
labs(y = NULL, x = NULL,
title = "What are the average ESG scores per sector?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
esg_scores_sector|>
mutate(controvery_relative = controversy_level - mean(controversy_level)) |>
ggplot(aes(y = reorder(sector, -controvery_relative),
x = controvery_relative, fill = (controvery_relative < 0))) +
geom_bar(stat = "identity", position = "dodge") +
theme_minimal() + theme(legend.position = "none") +
coord_cartesian(xlim = c(-1.5, 1.5)) +
labs(y = NULL, x = NULL,
title = "What is the average sector-level controversy relative to overall controversy?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
esg_data
esg_scores_sector <- esg_data|>
group_by(sector)|>
summarize(companies = n(),
coverage = sum(!is.na(total_esg_score)) / n(),
across(c(contains("score"), controversy_level),
~mean(., na.rm = TRUE)))|>
arrange(-coverage)
esg_scores_sector|>
mutate(controversy_relative = controversy_level - mean(controversy_level)) |>
ggplot(aes(y = reorder(sector, -controvery_relative),
x = controvery_relative, fill = (controvery_relative < 0))) +
geom_bar(stat = "identity", position = "dodge") +
theme_minimal() + theme(legend.position = "none") +
coord_cartesian(xlim = c(-1.5, 1.5)) +
labs(y = NULL, x = NULL,
title = "What is the average sector-level controversy relative to overall controversy?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
esg_scores_sector|>
mutate(controversy_relative = controversy_level - mean(controversy_level)) |>
ggplot(aes(y = reorder(sector, -controversy_relative),
x = controvery_relative, fill = (controversy_relative < 0))) +
geom_bar(stat = "identity", position = "dodge") +
theme_minimal() + theme(legend.position = "none") +
coord_cartesian(xlim = c(-1.5, 1.5)) +
labs(y = NULL, x = NULL,
title = "What is the average sector-level controversy relative to overall controversy?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
esg_scores_sector|>
mutate(controversy_relative = controversy_level - mean(controversy_level)) |>
ggplot(aes(y = reorder(sector, -controversy_relative),
x = controversy_relative, fill = (controversy_relative < 0))) +
geom_bar(stat = "identity", position = "dodge") +
theme_minimal() + theme(legend.position = "none") +
coord_cartesian(xlim = c(-1.5, 1.5)) +
labs(y = NULL, x = NULL,
title = "What is the average sector-level controversy relative to overall controversy?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of August 2020")
?map
esg_pages <- symbols |>
# slice(1) |>
mutate(sustainability_page = map(symbol, ~scrape_sustainability_page(., agent),
.progress = TRUE))
rlang::last_trace()
library(furrr)
plan(multisession)
#| eval: false
esg_pages <- symbols |>
mutate(
sustainability_page = future_map(
symbol, ~scrape_sustainability_page(., agent), .progress = TRUE
)
)
for (j in 1:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
write_rds(page, paste0("data/", symbols$symbol[j], ".rds"))
}
#| eval: false
for (j in 60:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
write_rds(page, paste0("data/", symbols$symbol[j], ".rds"))
}
#| eval: false
for (j in 61:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
write_rds(page, paste0("data/", symbols$symbol[j], ".rds"))
}
pages <- list.files("data/")
pages |>
map(~extract_esg_data(read_rds(.)))
pages <- list.files("data/", full.names = TRUE)
pages |>
map(~extract_esg_data(read_rds(.)))
page <- read_rds(pages[1])
page
page
page <- scrape_sustainability_page(symbols$symbol[j], agent)
page
extract_esg_data(page)
esg_data <- extract_esg_data(page)
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
for (j in 1:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
esg_data <- extract_esg_data(page)
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
}
esg_data <- list.files("data/", full.names = TRUE) |>
map_df(read_rds)
esg_data
extract_esg_data <- function(symbol, page) {
scrape_date <- Sys.time()
total_esg_score <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[1]/div/div[1]/div/div[2]/div[1]')|>
html_text()|>
parse_number()
total_esg_percentile <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[1]/div/div[1]/div/div[2]/div[2]/span')|>
html_text()|>
parse_number()
environment_risk_score <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[1]/div/div[2]/div/div[2]/div[1]')|>
html_text()|>
parse_number()
social_risk_score <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[1]/div/div[3]/div/div[2]/div[1]')|>
html_text()|>
parse_number()
governance_risk_score <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[1]/div/div[4]/div/div[2]/div[1]')|>
html_text()|>
parse_number()
controversy_level <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[2]/div[2]/div/div/div/div[1]/div')|>
html_text()|>
parse_number()
last_update_date <- page|>
html_node(xpath = '//*[@id="Col1-0-Sustainability-Proxy"]/section/div[3]/span[2]/span')|>
html_text()
last_update_date <- str_remove(last_update_date, "Last updated on ")
tibble(
symbol,
scrape_date,
total_esg_score,
environment_risk_score,
social_risk_score,
governance_risk_score,
controversy_level,
last_update_date
)
}
#| eval: false
for (j in 1:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
esg_data <- extract_esg_data(symbols$symbol[j], page)
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
}
j = 137
page <- scrape_sustainability_page(symbols$symbol[j], agent)
esg_data <- extract_esg_data(symbols$symbol[j], page)
esg_data
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
#| eval: false
for (j in 138:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
esg_data <- extract_esg_data(symbols$symbol[j], page)
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
}
#| eval: false
for (j in 427:nrow(symbols)) {
page <- scrape_sustainability_page(symbols$symbol[j], agent)
esg_data <- extract_esg_data(symbols$symbol[j], page)
write_rds(esg_data, paste0("data/esg_data_", symbols$symbol[j], ".rds"))
}
esg_data <- list.files("data/", full.names = TRUE) |>
map_df(read_rds)
esg_data
write_rds(esg_data, "posts/scraping-esg-data-from-yahoo-finance/esg_data.rds")
esg_data
esg_scores_sector <- symbols |>
left_join(esg_data, join_by(symbol)) |>
group_by(sector)|>
summarize(companies = n(),
coverage = sum(!is.na(total_esg_score)) / n(),
across(c(contains("score"), controversy_level),
~mean(., na.rm = TRUE)))|>
arrange(-coverage)
esg_scores_sector|>
pivot_longer(cols = contains("score"))|>
mutate(name = str_remove_all(name, "_"),
name = factor(name),
sector = tidytext::reorder_within(sector, -value, name))|>
ggplot(aes(y = sector, x = value, fill = name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~name, scales = "free_y") +
theme_minimal() +
tidytext::scale_y_reordered() +
geom_text(aes(label = round(value, 0)), hjust = 1.1, color = "white") +
labs(y = NULL, x = NULL,
title = "What are the average ESG scores per sector?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of November 2023")
esg_scores_sector|>
pivot_longer(cols = contains("score"))|>
mutate(name = str_replace_all(name, "_", " "),
name = factor(name),
sector = tidytext::reorder_within(sector, -value, name))|>
ggplot(aes(y = sector, x = value, fill = name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~name, scales = "free_y") +
theme_minimal() +
tidytext::scale_y_reordered() +
geom_text(aes(label = round(value, 0)), hjust = 1.1, color = "white") +
labs(y = NULL, x = NULL,
title = "What are the average ESG scores per sector?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of November 2023")
esg_scores_sector|>
pivot_longer(cols = contains("score"))|>
mutate(name = str_to_title(str_replace_all(name, "_", " ")),
name = factor(name),
sector = tidytext::reorder_within(sector, -value, name))|>
ggplot(aes(y = sector, x = value, fill = name)) +
geom_col(show.legend = FALSE) +
facet_wrap(~name, scales = "free_y") +
theme_minimal() +
tidytext::scale_y_reordered() +
geom_text(aes(label = round(value, 0)), hjust = 1.1, color = "white") +
labs(y = NULL, x = NULL,
title = "What are the average ESG scores per sector?",
subtitle = "Based on Yahoo Finance and S&P 500 data as of November 2023")
nrow(na.omit(esg_data)) / nrow(esg_data)
dax_raw <- tq_get("^GDAXI", get = "stock.prices",
from = "1988-07-01", to = "2023-10-30")
library(tidyverse)  # for grammar
library(tidyquant)  # for data download
install.packages("tidyquant")
library(tidyquant)  # for data download
library(scales)     # for pretty breaks in figures
dax_raw <- tq_get("^GDAXI", get = "stock.prices",
from = "1988-07-01", to = "2023-10-30")
dax <- dax_raw %>%
select(date, price = adjusted)
dax <- dax %>%
arrange(date) %>%
fill(price, .direction = "down")
dax %>%
ggplot(aes(x = date, y = price)) +
geom_line() +
labs(x = "", y = "Adjusted Price") +
scale_x_date(expand = c(0, 0), breaks = "5 years") +
scale_y_continuous(breaks = pretty_breaks()) +
theme_classic()
dax_monthly <- dax %>%
mutate(year = year(date),
month = month(date)) %>%
group_by(year, month) %>%
slice(which.max(date)) %>%
ungroup() %>%
arrange(date) %>%
mutate(ret = (log(price) - lag(log(price))) * 100) %>%
na.omit()
nrow(dax_monthly)
dax %>%
ggplot(aes(x = date, y = price)) +
geom_line() +
labs(x = "", y = "Adjusted Price") +
scale_x_date(expand = c(0, 0), breaks = "5 years") +
scale_y_continuous(breaks = pretty_breaks()) +
theme_classic()
dax_monthly <- dax %>%
mutate(year = year(date),
month = month(date)) %>%
group_by(year, month) %>%
slice(which.max(date)) %>%
ungroup() %>%
arrange(date) %>%
mutate(ret = (log(price) - lag(log(price))) * 100) %>%
na.omit()
nrow(dax_monthly)
dax_monthly <- dax %>%
mutate(year = year(date),
month = month(date)) %>%
group_by(year, month) %>%
slice(which.max(date)) %>%
ungroup() %>%
arrange(date) %>%
mutate(ret = price / lag(price) - 1) %>%
drop_na()
nrow(dax_monthly)
dax
dax_monthly <- dax %>%
mutate(year = year(date),
month = month(date)) %>%
group_by(year, month) %>%
filter(date == max(date)) %>%
ungroup() %>%
arrange(date) %>%
mutate(ret = price / lag(price) - 1) %>%
drop_na()
dax_monthly
nrow(dax_monthly)
dax_monthly %>%
group_by(`Month` = month_factor) %>%
summarize(Mean = mean(excess_ret),
SD = sd(excess_ret),
Q05 = quantile(excess_ret, 0.05),
Q95 = quantile(excess_ret, 0.95),
`t-Statistic` = sqrt(n()) * mean(excess_ret) / sd(excess_ret))
dax_monthly %>%
group_by(`Month` = month) %>%
summarize(Mean = mean(excess_ret),
SD = sd(excess_ret),
Q05 = quantile(excess_ret, 0.05),
Q95 = quantile(excess_ret, 0.95),
`t-Statistic` = sqrt(n()) * mean(excess_ret) / sd(excess_ret))
dax_monthly %>%
group_by(month) %>%
summarize(Mean = mean(excess_ret),
SD = sd(excess_ret),
Q05 = quantile(excess_ret, 0.05),
Q95 = quantile(excess_ret, 0.95),
`t-Statistic` = sqrt(n()) * mean(excess_ret) / sd(excess_ret))
library(frenchdata)
factors_ff3_monthly_raw <- download_french_data("Fama/French 3 Factors")
factors_ff3_monthly <- factors_ff3_monthly_raw$subsets$data[[1]] |>
mutate(
date = ymd(str_c(date, "01")),
year = year(date),
month = month(date),
rf = as.numeric(RF) / 100,
.keep = "none"
)
factors_ff3_monthly
factors_ff3_monthly <- factors_ff3_monthly_raw$subsets$data[[1]] |>
mutate(
year = year(ymd(str_c(date, "01"))),
month = month(ymd(str_c(date, "01"))),
rf = as.numeric(RF) / 100,
.keep = "none"
)
factors_ff3_monthly
risk_free_monthly <- factors_ff3_monthly_raw$subsets$data[[1]] |>
mutate(
year = year(ymd(str_c(date, "01"))),
month = month(ymd(str_c(date, "01"))),
rf = as.numeric(RF) / 100,
.keep = "none"
)
dax_monthly |>
left_join(risk_free_monthly, join_by(year, month))
dax_monthly |>
left_join(risk_free_monthly, join_by(year, month)) |>
mutate(ret_excess = ret - rf)
dax_monthly <- dax_monthly |>
left_join(risk_free_monthly, join_by(year, month)) |>
mutate(ret_excess = ret - rf)
dax_monthly
dax_monthly %>%
group_by(month) %>%
summarize(Mean = mean(excess_ret),
SD = sd(excess_ret),
Q05 = quantile(excess_ret, 0.05),
Q95 = quantile(excess_ret, 0.95),
`t-Statistic` = sqrt(n()) * mean(excess_ret) / sd(excess_ret))
dax_monthly %>%
group_by(month) %>%
summarize(Mean = mean(ret_excess),
SD = sd(ret_excess),
Q05 = quantile(ret_excess, 0.05),
Q95 = quantile(ret_excess, 0.95),
`t-Statistic` = sqrt(n()) * mean(ret_excess) / sd(ret_excess))
dax_monthly %>%
drop_na(ret_excess) |>
group_by(month) %>%
summarize(Mean = mean(ret_excess),
SD = sd(ret_excess),
Q05 = quantile(ret_excess, 0.05),
Q95 = quantile(ret_excess, 0.95),
`t-Statistic` = sqrt(n()) * mean(ret_excess) / sd(ret_excess))
dax_monthly %>%
drop_na(ret_excess) |>
group_by(Month = month) %>%
summarize(Mean = mean(ret_excess),
SD = sd(ret_excess),
Q05 = quantile(ret_excess, 0.05),
Q95 = quantile(ret_excess, 0.95),
`t-Statistic` = sqrt(n()) * mean(ret_excess) / sd(ret_excess))
summary(lm(excess_ret ~ month, data = dax_monthly), robust = TRUE)
summary(lm(ret_excess ~ month, data = dax_monthly), robust = TRUE)
summary(lm(ret_excess ~ factor(month), data = dax_monthly), robust = TRUE)
halloween_months <- c(11, 12, 1, 2, 3, 4)
seasonality_months <- c(10, 11, 12, 1, 2, 3, 4, 5, 6)
dax_monthly <- dax_monthly %>%
mutate(halloween = if_else(month %in% halloween_months, 1L, 0L),
seasonality = if_else(month %in% seasonality_months, 1L, 0L))
summary(lm(ret_excess ~ halloween, data = dax_monthly), robust = TRUE)
summary(lm(ret_excess ~ seasonality, data = dax_monthly), robust = TRUE)
dax_monthly <- dax_monthly %>%
mutate(excess_ret_halloween = if_else(halloween == 1, ret, rf),
excess_ret_halloween_short = if_else(halloween == 1, ret, -ret),
excess_ret_seasonality = if_else(seasonality == 1, ret, rf),
excess_ret_seasonality_short = if_else(seasonality == 1, ret, -ret))
dax_monthly %>%
group_by(year) %>%
summarize(`Buy and Hold` = sum(excess_ret),
`Seasonality` = sum(excess_ret_seasonality),
`Seasonality-Short` = sum(excess_ret_seasonality_short),
`Halloween` = sum(excess_ret_halloween),
`Halloween-Short` = sum(excess_ret_halloween_short)) %>%
pivot_longer(-year, names_to = "strategy", values_to = "excess_ret") %>%
ggplot(aes(x = year, group = strategy)) +
geom_col(aes(y = excess_ret, fill = strategy), position = "dodge") +
labs(x = "", y = "Annual Excess Return (in %)", fill = "Strategy") +
scale_x_continuous(expand = c(0, 0), breaks = pretty_breaks()) +
theme_classic()
dax_monthly <- dax_monthly %>%
mutate(ret_excess_halloween = if_else(halloween == 1, ret, rf),
ret_excess_halloween_short = if_else(halloween == 1, ret, -ret),
ret_excess_seasonality = if_else(seasonality == 1, ret, rf),
ret_excess_seasonality_short = if_else(seasonality == 1, ret, -ret))
dax_monthly %>%
group_by(year) %>%
summarize(`Buy and Hold` = sum(ret_excess),
`Seasonality` = sum(ret_excess_seasonality),
`Seasonality-Short` = sum(ret_excess_seasonality_short),
`Halloween` = sum(ret_excess_halloween),
`Halloween-Short` = sum(ret_excess_halloween_short)) %>%
pivot_longer(-year, names_to = "strategy", values_to = "ret_excess") %>%
ggplot(aes(x = year, group = strategy)) +
geom_col(aes(y = ret_excess, fill = strategy), position = "dodge") +
labs(x = "", y = "Annual Excess Return (in %)", fill = "Strategy") +
scale_x_continuous(expand = c(0, 0), breaks = pretty_breaks()) +
theme_classic()
dax_monthly %>%
arrange(date) %>%
mutate(`Buy and Hold` = 100 + cumsum(excess_ret),
`Seasonality` = 100 + cumsum(excess_ret_seasonality),
`Seasonality-Short` = 100 + cumsum(excess_ret_seasonality_short),
`Halloween` = 100 + cumsum(excess_ret_halloween),
`Halloween-Short` = 100 + cumsum(excess_ret_halloween_short)) %>%
select(date, `Buy and Hold`, `Seasonality`, `Seasonality-Short`,
`Halloween`, `Halloween-Short`) %>%
pivot_longer(-date, names_to = "strategy", values_to = "cum_excess_ret") %>%
ggplot(aes(x = date)) +
geom_line(aes(y = cum_excess_ret, color = strategy)) +
scale_x_date(expand = c(0, 0), breaks = pretty_breaks()) +
scale_y_continuous(breaks = pretty_breaks()) +
labs(x = "", y = "Cumulative Excess Return (in %)", color = "Strategy") +
theme_classic()
dax_monthly %>%
arrange(date) %>%
mutate(`Buy and Hold` = 100 + cumsum(ret_excess),
`Seasonality` = 100 + cumsum(ret_excess_seasonality),
`Seasonality-Short` = 100 + cumsum(ret_excess_seasonality_short),
`Halloween` = 100 + cumsum(ret_excess_halloween),
`Halloween-Short` = 100 + cumsum(ret_excess_halloween_short)) %>%
select(date, `Buy and Hold`, `Seasonality`, `Seasonality-Short`,
`Halloween`, `Halloween-Short`) %>%
pivot_longer(-date, names_to = "strategy", values_to = "cum_ret_excess") %>%
ggplot(aes(x = date)) +
geom_line(aes(y = cum_ret_excess, color = strategy)) +
scale_x_date(expand = c(0, 0), breaks = pretty_breaks()) +
scale_y_continuous(breaks = pretty_breaks()) +
labs(x = "", y = "Cumulative Excess Return (in %)", color = "Strategy") +
theme_classic()
sharpe_ratio <- function(x) {
sqrt(12) *  mean(x) / sd(x)
}
dax_monthly %>%
arrange(date) %>%
summarize(`Buy and Hold` = sharpe_ratio(ret_excess),
`Seasonality` = sharpe_ratio(ret_excess_seasonality),
`Seasonality-Short` = sharpe_ratio(ret_excess_seasonality_short),
`Halloween` = sharpe_ratio(ret_excess_halloween),
`Halloween-Short` = sharpe_ratio(ret_excess_halloween_short))
dax_monthly
dax_monthly
dax_monthly |>
group_by(month) |>
summarize(mean(ret))
dax_monthly |>
group_by(month) |>
summarize(ret = mean(ret)) |>
ggplot(aes(x = month, y = ret)) +
geom_col()
dax_monthly |>
group_by(month) |>
summarize(ret = mean(ret)) |>
ggplot(aes(x = month, y = ret, fill = ret > 0)) +
geom_col()
ggplot(dax_monthly, aes(x = month, y = ret)) +
ggdist::stat_halfeye(
adjust = .5,
width = .6,
.width = 0,
justification = -.3,
point_colour = NA) +
geom_boxplot(
width = .25,
outlier.shape = NA
) +
geom_point(
size = 1.5,
alpha = .2,
position = position_jitter(
seed = 1, width = .1
)
)
install.packages("ggdist")
